#### 计算机视觉历史背景

​	60年代： David Marr 表示 ：为了拍摄一幅图像，并获得视觉世界的最终全面地3D表现，我们必须经历几个阶段：

​	第一个阶段：“原始草图”，大部分边缘、端点、虚拟线条、曲线、边界等都被用其它元素来表示，这是受到神经科学家的启发，视觉处理的早期阶段有很多关于向边缘的简单结构。

​	第二个阶段：边缘和曲线之后的下一步是 “2.5维草图”，我们开始将表面深度信息层 或 视觉场景的不连续型拼凑在一起

​	第三个阶段：最终将所有的内容放在一起，并在表面和体积图等分层组织了一个3d模型。

​	这是一个非常理想化的思想过程，非常直观的阐述如何解析视觉信息。

​	70年代：如何越过简单的块状世界，开始识别和表示现实世界。两种思想：广义圆柱体 和 图形结构：

![1533188792357](广义圆柱体和图形结构.png)

​	基本思想都是每个对象都由简单的几何图单位组成，例如：一个人通过广义的圆柱形形状拼接在一起，或者 人也可以由一些关键元素按照不同的间距组合在一起。他们都是将物体的复杂结构简化成一个由更简单的形状和几何结构的集合体。

​	80年代：重建或者识别由简单的物体结构组成的是视觉空间。 

​	曾经的这些努力都试图去思考，从60年代到80年代，计算机视觉的任务是什么，要解决物体识别的问题非常难，这些都是非常有脑洞，有野心的尝试，但是他们仅仅停留在简单样本的阶段，或者很少的样本，没有产生很大的进展，没有输出可以在现实世界有用的东西。

​	在解决视觉问题过程中出现的问题时：

​	一个很重要的问题是：如果目标识别太难了，那么我们首先要做的是目标分割，这个任务就是把一张图片中的像素点归类到有意义的区域。这个过程就叫做图像分割。

![1533191176270](MeaningfulAreas.png)

​	另一个问题，先于其他计算机视觉问题有进展：面部识别 ，1999-2000年机器学习技术，特别是统计机器学习方法开始加速发展，出现了一些方法：支持向量机模型，boosting方法，图模型，有一种特别工作做出了很多贡献，就是使用AdaBoost算法进行实时面部检测。

​	关于如何才能更好地目标识别，这是一个我们可以继续研究的领域。90年代末到2000年的前十年有一个非常有影响力的思想方法就是基于特征的目标识别，一个影响深远的工作叫SIFT特征，思路就是去匹配整个目标，通过观察目标的某些部分，某些特征，它们往往能够在变化中具有表现性和不变性 。

​	所以目标识别首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，它比匹配整个目标要容易很多。

![1533190901912](SIFT.png)

​	使用相同的构成要素特征和图片中的表现特征。我们这个领域的另一进展是识别整幅图的场景，这里有一个算法作为例子，叫做 空间金字塔匹配，背后的思想是：图片里面有各种特征，这些特征可以告诉我们这是哪种场景。这个算法从图片的各部分个像素抽取特征，并把他们放在一起，作为一个特征描述符，然后在特征描述符上做一个支持向量机。

​	在认知人类方面，方向梯度直方图  和  可变形部件模型。

​	从60-70-80年代，图片质量一直在变化 ，随着互联网和数码相机的发展，计算机视觉的研究也能拥有更好的数据了，计算机视觉在21世纪早期，指出一个非常重要的基本问题，这个问题不仅必须要解决，而且是非常重要的识别问题，就是目标识别。

​	目标识别方面取得的成果，其中最有影响力的标注数据集之一叫：PASCAL Visual Object Challenge 这个数据集有20个类别，数据集中的每种类别有成千上万张图片，现场不同的团队开发算法来和数据测试集做对抗训练来看有没有优化 

![1533192925411](PASCALVisualObjectChallenge.png)

​	2012年：我们是否具备了识别真实世界中的每一个物体的能力，或者说大部分物体，这个问题也是由机器学习中的一个现象驱动的，就是大部分的机器学习算法，无论是图模型、支持向量机或者AdaBoost 都很可能会在训练过程中 过拟合，部分原因是可视化的数据非常复杂，正因为它们太复杂了，我们的模型往往维数比较高，输入的是高维模型，则还有一堆参数要调优，当我们的训练数据量不够时，很快就会产生过拟合现象，这样我们就无法很好地泛化。

​	因此就是有两方面动力，一是我们单纯就是想识别自然世界中的万物，二是要回归机器学习，克服机器学习的瓶颈，过拟合问题。

​	2012年出现 一种算法：卷积神经网络模型~

